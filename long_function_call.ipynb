{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f32bcf-dfdb-496a-80d8-10a090bdc77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import yaml\n",
    "def read_config(path):\n",
    "    \"\"\"\n",
    "    Reads API key from a configuration file.\n",
    "\n",
    "    This function opens a configuration file named \"apikeys.yml\", reads the API key for OpenAI\n",
    "\n",
    "    Returns:\n",
    "    api_key (str): The API key for the Amadeus Flights API.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the directory of the current script\n",
    "    script_dir = path\n",
    "\n",
    "    # Construct the full path to the configuration file\n",
    "    file_path = os.path.join(script_dir, \"apikeys.yml\")\n",
    "\n",
    "    with open(file_path, 'r') as stream:\n",
    "        configs = yaml.safe_load(stream)\n",
    "        API_KEY = configs['openai']['api_key']\n",
    "            \n",
    "    return API_KEY\n",
    "path = r\"C:\\Users\\johna\\OneDrive\\Documents\\api_keys\"  # Change to the location of your apikeys.yml\n",
    "API_KEY = read_config(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864bf3ba-14a0-4079-b4dc-2795a14afe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "from haystack.utils import convert_files_to_docs\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# pre-process docs \n",
    "def preprocess_docs(doc_dir):\n",
    "    all_docs = convert_files_to_docs(dir_path=doc_dir)\n",
    "    preprocessor = PreProcessor(\n",
    "        clean_empty_lines=True,\n",
    "        clean_whitespace=True,\n",
    "        clean_header_footer=False,\n",
    "        split_by=\"word\",\n",
    "        split_respect_sentence_boundary=True,\n",
    "        split_overlap=30, \n",
    "        split_length=100\n",
    "    )\n",
    "    docs = preprocessor.process(all_docs)\n",
    "    print(f\"n_files_input: {len(all_docs)}\\nn_docs_output: {len(docs)}\")\n",
    "    return docs\n",
    "\n",
    "\n",
    "# create FAISS\n",
    "def vector_stores(docs):\n",
    "    engine = create_engine('sqlite:///C:/Users/johna/anaconda3/envs/longfunctioncall_env/long_functioncall/database/database.db')  # change to your local directory\n",
    "    try:\n",
    "        # Attempt to drop the table\n",
    "        engine.execute(\"DROP TABLE document\")\n",
    "    except Exception as e:\n",
    "        # Catch any exceptions, likely due to the table not existing\n",
    "        print(f\"Exception occurred while trying to drop the table: {e}\")\n",
    "    \n",
    "    document_store = FAISSDocumentStore(sql_url='sqlite:///C:/Users/johna/anaconda3/envs/longfunctioncall_env/long_functioncall/database/database.db', faiss_index_factory_str=\"Flat\", embedding_dim=768) # change to your local directory\n",
    "    document_store.write_documents(docs)\n",
    "    \n",
    "    return document_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e4ccb6-cdc5-46ff-9d7e-bb5b1be244d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:   0%|                                                                           | 0/1 [00:00<?, ?docs/s]We found one or more sentences whose word count is higher than the split length.\n",
      "Preprocessing: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.61docs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_files_input: 1\n",
      "n_docs_output: 1176\n",
      "Exception occurred while trying to drop the table: (sqlite3.OperationalError) no such table: document\n",
      "[SQL: DROP TABLE document]\n",
      "(Background on this error at: https://sqlalche.me/e/14/e3q8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing Documents: 10000it [00:02, 3442.53it/s]                                                                        \n"
     ]
    }
   ],
   "source": [
    "doc_dir = r\"C:\\Users\\johna\\anaconda3\\envs\\longfunctioncall_env\\long_functioncall\\knowledge_base\"\n",
    "docs = preprocess_docs(doc_dir)\n",
    "document_store = vector_stores(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e78c7ca7-3233-4bd4-a63f-442637fc4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from haystack.nodes.base import BaseComponent\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "class OpenAIFunctionCall(BaseComponent):\n",
    "    outgoing_edges = 1\n",
    "\n",
    "    def run(self, documents: List[str]):\n",
    "        \n",
    "        # Try to extract the content and print the first few content strings\n",
    "        try:\n",
    "            document_content_list = [doc.content for doc in documents]\n",
    "            print(\"documents extracted\")\n",
    "            document_content = \" \".join(document_content_list)\n",
    "        except Exception as e:\n",
    "            print(\"Error extracting content:\", e)\n",
    "            return\n",
    "        functions = [\n",
    "            {\n",
    "                \"name\": \"write_to_df\",\n",
    "                \"description\": \"write the fund details to a dataframe\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"prr\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The FCA product reference number which will be six or seven digits\"\n",
    "                        },\n",
    "                        \"investment_objective\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"You should return the investment objective of the fund. This is likely to be something like this: The Fund aims to grow your investment over t – t + delta t years\"\n",
    "                        },\n",
    "                        \"investment_policy\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Return a summary of the fund's investment policy, no more than two sentences.\"\n",
    "                        },\n",
    "                        \"investment_strategy\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Return a summary of the fund's investment strategy, no more than two sentences.\"\n",
    "                        },\n",
    "                        \"ESG\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Return either True, or False. True if the fund is an ESG fund, False otherwise.\"\n",
    "                        },\n",
    "                        \"fund_name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Return the name of the fund\"\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"prr\", \n",
    "                             \"investment_objective\", \n",
    "                             \"investment_policy\",\n",
    "                             \"investment_strategy\",\n",
    "                             \"ESG\",\n",
    "                             \"fund_name\"]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        openai.api_key = API_KEY\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=[{\"role\": \"system\", \"content\": document_content}],\n",
    "            functions=functions,\n",
    "            function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "        )\n",
    "\n",
    "        function_call_args = json.loads(response[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"])\n",
    "        \n",
    "        return function_call_args, \"output_1\"\n",
    "\n",
    "    def run_batch(self, documents: List[str]):\n",
    "        # You can either process multiple documents in a batch here or simply loop over the run method\n",
    "        results = []\n",
    "        for document_content in document_content:\n",
    "            result, _ = self.run(document_content)\n",
    "            results.append(result)\n",
    "        return results, \"output_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5e9984e-0624-4398-a291-ee1a91436646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating Embedding:   0%|                                                                  | 0/1163 [00:00<?, ? docs/s]\n",
      "Batches:   0%|                                                                                  | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:   3%|██                                                                        | 1/37 [00:35<21:13, 35.37s/it]\u001b[A\n",
      "Batches:   5%|████                                                                      | 2/37 [00:46<12:12, 20.94s/it]\u001b[A\n",
      "Batches:   8%|██████                                                                    | 3/37 [00:57<09:20, 16.47s/it]\u001b[A\n",
      "Batches:  11%|████████                                                                  | 4/37 [01:06<07:29, 13.63s/it]\u001b[A\n",
      "Batches:  14%|██████████                                                                | 5/37 [01:15<06:20, 11.90s/it]\u001b[A\n",
      "Batches:  16%|████████████                                                              | 6/37 [01:24<05:34, 10.78s/it]\u001b[A\n",
      "Batches:  19%|██████████████                                                            | 7/37 [01:31<04:47,  9.58s/it]\u001b[A\n",
      "Batches:  22%|████████████████                                                          | 8/37 [01:38<04:14,  8.77s/it]\u001b[A\n",
      "Batches:  24%|██████████████████                                                        | 9/37 [01:44<03:43,  7.97s/it]\u001b[A\n",
      "Batches:  27%|███████████████████▋                                                     | 10/37 [01:50<03:16,  7.29s/it]\u001b[A\n",
      "Batches:  30%|█████████████████████▋                                                   | 11/37 [01:56<03:04,  7.08s/it]\u001b[A\n",
      "Batches:  32%|███████████████████████▋                                                 | 12/37 [02:02<02:45,  6.64s/it]\u001b[A\n",
      "Batches:  35%|█████████████████████████▋                                               | 13/37 [02:08<02:36,  6.51s/it]\u001b[A\n",
      "Batches:  38%|███████████████████████████▌                                             | 14/37 [02:14<02:28,  6.44s/it]\u001b[A\n",
      "Batches:  41%|█████████████████████████████▌                                           | 15/37 [02:20<02:14,  6.13s/it]\u001b[A\n",
      "Batches:  43%|███████████████████████████████▌                                         | 16/37 [02:25<02:03,  5.87s/it]\u001b[A\n",
      "Batches:  46%|█████████████████████████████████▌                                       | 17/37 [02:30<01:52,  5.62s/it]\u001b[A\n",
      "Batches:  49%|███████████████████████████████████▌                                     | 18/37 [02:36<01:50,  5.82s/it]\u001b[A\n",
      "Batches:  51%|█████████████████████████████████████▍                                   | 19/37 [02:42<01:44,  5.82s/it]\u001b[A\n",
      "Batches:  54%|███████████████████████████████████████▍                                 | 20/37 [02:47<01:33,  5.49s/it]\u001b[A\n",
      "Batches:  57%|█████████████████████████████████████████▍                               | 21/37 [02:52<01:24,  5.31s/it]\u001b[A\n",
      "Batches:  59%|███████████████████████████████████████████▍                             | 22/37 [02:58<01:21,  5.46s/it]\u001b[A\n",
      "Batches:  62%|█████████████████████████████████████████████▍                           | 23/37 [03:03<01:17,  5.52s/it]\u001b[A\n",
      "Batches:  65%|███████████████████████████████████████████████▎                         | 24/37 [03:08<01:09,  5.31s/it]\u001b[A\n",
      "Batches:  68%|█████████████████████████████████████████████████▎                       | 25/37 [03:13<01:00,  5.02s/it]\u001b[A\n",
      "Batches:  70%|███████████████████████████████████████████████████▎                     | 26/37 [03:17<00:54,  4.99s/it]\u001b[A\n",
      "Batches:  73%|█████████████████████████████████████████████████████▎                   | 27/37 [03:22<00:49,  4.91s/it]\u001b[A\n",
      "Batches:  76%|███████████████████████████████████████████████████████▏                 | 28/37 [03:27<00:43,  4.85s/it]\u001b[A\n",
      "Batches:  78%|█████████████████████████████████████████████████████████▏               | 29/37 [03:31<00:37,  4.66s/it]\u001b[A\n",
      "Batches:  81%|███████████████████████████████████████████████████████████▏             | 30/37 [03:35<00:31,  4.50s/it]\u001b[A\n",
      "Batches:  84%|█████████████████████████████████████████████████████████████▏           | 31/37 [03:41<00:29,  4.85s/it]\u001b[A\n",
      "Batches:  86%|███████████████████████████████████████████████████████████████▏         | 32/37 [03:45<00:22,  4.60s/it]\u001b[A\n",
      "Batches:  89%|█████████████████████████████████████████████████████████████████        | 33/37 [03:49<00:17,  4.47s/it]\u001b[A\n",
      "Batches:  92%|███████████████████████████████████████████████████████████████████      | 34/37 [03:53<00:12,  4.23s/it]\u001b[A\n",
      "Batches:  95%|█████████████████████████████████████████████████████████████████████    | 35/37 [03:57<00:08,  4.17s/it]\u001b[A\n",
      "Batches:  97%|███████████████████████████████████████████████████████████████████████  | 36/37 [04:00<00:03,  4.00s/it]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████| 37/37 [04:01<00:00,  6.54s/it]\u001b[A\n",
      "Documents Processed: 10000 docs [04:02, 41.29 docs/s]                                                                  \n"
     ]
    }
   ],
   "source": [
    "# create our pipeline\n",
    "from haystack import Pipeline\n",
    "from haystack.nodes import EmbeddingRetriever\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "    document_store=document_store,\n",
    "    embedding_model=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "688beb35-3976-460f-a917-0758cef56d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents extracted\n"
     ]
    }
   ],
   "source": [
    "p = Pipeline()\n",
    "p.add_node(component=retriever, name=\"retriever\", inputs=[\"Query\"])\n",
    "p.add_node(component=OpenAIFunctionCall(), name=\"OpenAIFunctionCall\", inputs=[\"retriever\"])\n",
    "res = p.run(query=\"Get the details for the Global Sustain Fund\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dab918e3-90aa-4775-94ba-c454548e8f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prr = res['prr']\n",
    "investment_objective = res['investment_objective']\n",
    "investment_strategy = res['investment_strategy']\n",
    "investment_policy = res['investment_policy']\n",
    "ESG = res['ESG']\n",
    "fund_name = res['fund_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ce98aa5c-30e6-4fbc-baf7-56dcd850e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def update_dataframe(prr, investment_objective, investment_strategy, investment_policy, ESG, fund_name):\n",
    "\n",
    "    # Define the columns\n",
    "    columns = ['prr', 'fund_name', 'investment_objective', 'investment_strategy', 'investment_policy', 'ESG']\n",
    "    \n",
    "    # Create an empty DataFrame with the specified columns\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    # Create a dictionary for the new record\n",
    "    new_record = {\n",
    "        'prr': prr,\n",
    "        'fund_name': fund_name,\n",
    "        'investment_objective': investment_objective,\n",
    "        'investment_strategy': investment_strategy,\n",
    "        'investment_policy': investment_policy,\n",
    "        'ESG': ESG\n",
    "    }\n",
    "\n",
    "    # Check if a record with the given prr already exists\n",
    "    if prr in df['prr'].values:\n",
    "        # Update the existing record\n",
    "        idx = df[df['prr'] == prr].index[0]\n",
    "        df.loc[idx] = new_record\n",
    "    else:\n",
    "        # Convert the new record to a DataFrame\n",
    "        new_df = pd.DataFrame([new_record])\n",
    "        # Concatenate the existing DataFrame with the new record\n",
    "        df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b4a37965-be21-48a6-8635-a9e51699ba9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prr</th>\n",
       "      <th>fund_name</th>\n",
       "      <th>investment_objective</th>\n",
       "      <th>investment_strategy</th>\n",
       "      <th>investment_policy</th>\n",
       "      <th>ESG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>914072</td>\n",
       "      <td>Global Sustain Fund</td>\n",
       "      <td>The Fund aims to grow your investment over 5-1...</td>\n",
       "      <td>The Investment Manager applies sustainability ...</td>\n",
       "      <td>The Fund invests at least 70% of its assets in...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prr            fund_name  \\\n",
       "0  914072  Global Sustain Fund   \n",
       "\n",
       "                                investment_objective  \\\n",
       "0  The Fund aims to grow your investment over 5-1...   \n",
       "\n",
       "                                 investment_strategy  \\\n",
       "0  The Investment Manager applies sustainability ...   \n",
       "\n",
       "                                   investment_policy   ESG  \n",
       "0  The Fund invests at least 70% of its assets in...  True  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = update_dataframe(prr, investment_objective, investment_strategy, investment_policy, ESG, fund_name)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b5f7eb-ca48-4a75-917a-f1f00135b59e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
