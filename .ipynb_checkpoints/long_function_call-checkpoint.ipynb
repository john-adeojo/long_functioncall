{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f32bcf-dfdb-496a-80d8-10a090bdc77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import yaml\n",
    "def read_config(path):\n",
    "    \"\"\"\n",
    "    Reads API key from a configuration file.\n",
    "\n",
    "    This function opens a configuration file named \"apikeys.yml\", reads the API key for OpenAI\n",
    "\n",
    "    Returns:\n",
    "    api_key (str): The API key for the Amadeus Flights API.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the directory of the current script\n",
    "    script_dir = path\n",
    "\n",
    "    # Construct the full path to the configuration file\n",
    "    file_path = os.path.join(script_dir, \"apikeys.yml\")\n",
    "\n",
    "    with open(file_path, 'r') as stream:\n",
    "        configs = yaml.safe_load(stream)\n",
    "        API_KEY = configs['openai']['api_key']\n",
    "            \n",
    "    return API_KEY\n",
    "path = r\"C:\\Users\\johna\\OneDrive\\Documents\\api_keys\"  # Change to the location of your apikeys.yml\n",
    "API_KEY = read_config(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864bf3ba-14a0-4079-b4dc-2795a14afe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "from haystack.utils import convert_files_to_docs\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# pre-process docs \n",
    "def preprocess_docs(doc_dir):\n",
    "    all_docs = convert_files_to_docs(dir_path=doc_dir)\n",
    "    preprocessor = PreProcessor(\n",
    "        clean_empty_lines=True,\n",
    "        clean_whitespace=True,\n",
    "        clean_header_footer=False,\n",
    "        split_by=\"word\",\n",
    "        split_respect_sentence_boundary=True,\n",
    "        split_overlap=30, \n",
    "        split_length=100\n",
    "    )\n",
    "    docs = preprocessor.process(all_docs)\n",
    "    print(f\"n_files_input: {len(all_docs)}\\nn_docs_output: {len(docs)}\")\n",
    "    return docs\n",
    "\n",
    "\n",
    "# create FAISS\n",
    "def vector_stores(docs):\n",
    "    engine = create_engine('sqlite:///C:/Users/johna/anaconda3/envs/longfunctioncall_env/long_functioncall/database/database.db')  # change to your local directory\n",
    "    try:\n",
    "        # Attempt to drop the table\n",
    "        engine.execute(\"DROP TABLE document\")\n",
    "    except Exception as e:\n",
    "        # Catch any exceptions, likely due to the table not existing\n",
    "        print(f\"Exception occurred while trying to drop the table: {e}\")\n",
    "    \n",
    "    document_store = FAISSDocumentStore(sql_url='sqlite:///C:/Users/johna/anaconda3/envs/longfunctioncall_env/long_functioncall/database/database.db', faiss_index_factory_str=\"Flat\", embedding_dim=768) # change to your local directory\n",
    "    document_store.write_documents(docs)\n",
    "    \n",
    "    return document_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e4ccb6-cdc5-46ff-9d7e-bb5b1be244d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:   0%|                                                                           | 0/1 [00:00<?, ?docs/s]We found one or more sentences whose word count is higher than the split length.\n",
      "Preprocessing: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.61docs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_files_input: 1\n",
      "n_docs_output: 1176\n",
      "Exception occurred while trying to drop the table: (sqlite3.OperationalError) no such table: document\n",
      "[SQL: DROP TABLE document]\n",
      "(Background on this error at: https://sqlalche.me/e/14/e3q8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing Documents: 10000it [00:02, 3442.53it/s]                                                                        \n"
     ]
    }
   ],
   "source": [
    "doc_dir = r\"C:\\Users\\johna\\anaconda3\\envs\\longfunctioncall_env\\long_functioncall\\knowledge_base\"\n",
    "docs = preprocess_docs(doc_dir)\n",
    "document_store = vector_stores(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e78c7ca7-3233-4bd4-a63f-442637fc4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from haystack.nodes.base import BaseComponent\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "class OpenAIFunctionCall(BaseComponent):\n",
    "    outgoing_edges = 1\n",
    "\n",
    "    def run(self, documents: List[str]):\n",
    "        \n",
    "        # Try to extract the content and print the first few content strings\n",
    "        try:\n",
    "            document_content_list = [doc.content for doc in documents]\n",
    "            print(\"documents extracted\")\n",
    "            document_content = \" \".join(document_content_list)\n",
    "        except Exception as e:\n",
    "            print(\"Error extracting content:\", e)\n",
    "            return\n",
    "        functions = [\n",
    "            {\n",
    "                \"name\": \"write_to_df\",\n",
    "                \"description\": \"write the fund details to a dataframe\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"prr\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The FCA product reference number which will be six or seven digits\"\n",
    "                        },\n",
    "                        \"investment_objective\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"You should return the investment objective of the fund. This is likely to be something like this: The Fund aims to grow your investment over t – t + delta t years\"\n",
    "                        },\n",
    "                        \"investment_policy\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Return a summary of the fund's investment policy, no more than two sentences.\"\n",
    "                        },\n",
    "                        \"investment_strategy\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Return a summary of the fund's investment strategy, no more than two sentences.\"\n",
    "                        },\n",
    "                        \"ESG\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Return either True, or False. True if the fund is an ESG fund, False otherwise.\"\n",
    "                        },\n",
    "                        \"fund_name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Return the name of the fund\"\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"prr\", \n",
    "                             \"investment_objective\", \n",
    "                             \"investment_policy\",\n",
    "                             \"investment_strategy\",\n",
    "                             \"ESG\",\n",
    "                             \"fund_name\"]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        openai.api_key = API_KEY\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=[{\"role\": \"system\", \"content\": document_content}],\n",
    "            functions=functions,\n",
    "            function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "        )\n",
    "\n",
    "        function_call_args = json.loads(response[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"])\n",
    "        \n",
    "        return function_call_args, \"output_1\"\n",
    "\n",
    "    def run_batch(self, documents: List[str]):\n",
    "        # You can either process multiple documents in a batch here or simply loop over the run method\n",
    "        results = []\n",
    "        for document_content in document_content:\n",
    "            result, _ = self.run(document_content)\n",
    "            results.append(result)\n",
    "        return results, \"output_1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9984e-0624-4398-a291-ee1a91436646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our pipeline\n",
    "from haystack import Pipeline\n",
    "from haystack.nodes import EmbeddingRetriever\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "    document_store=document_store,\n",
    "    embedding_model=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "688beb35-3976-460f-a917-0758cef56d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents extracted\n"
     ]
    }
   ],
   "source": [
    "p = Pipeline()\n",
    "p.add_node(component=retriever, name=\"retriever\", inputs=[\"Query\"])\n",
    "p.add_node(component=OpenAIFunctionCall(), name=\"OpenAIFunctionCall\", inputs=[\"retriever\"])\n",
    "res = p.run(query=\"Get the details for the Global Sustain Fund\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dab918e3-90aa-4775-94ba-c454548e8f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prr = res['prr']\n",
    "investment_objective = res['investment_objective']\n",
    "investment_strategy = res['investment_strategy']\n",
    "investment_policy = res['investment_policy']\n",
    "ESG = res['ESG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce98aa5c-30e6-4fbc-baf7-56dcd850e51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a37965-be21-48a6-8635-a9e51699ba9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
