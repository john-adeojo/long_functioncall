{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f32bcf-dfdb-496a-80d8-10a090bdc77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import yaml\n",
    "def read_config(path):\n",
    "    \"\"\"\n",
    "    Reads API key from a configuration file.\n",
    "\n",
    "    This function opens a configuration file named \"apikeys.yml\", reads the API key for OpenAI\n",
    "\n",
    "    Returns:\n",
    "    api_key (str): The API key for the Amadeus Flights API.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the directory of the current script\n",
    "    script_dir = path\n",
    "\n",
    "    # Construct the full path to the configuration file\n",
    "    file_path = os.path.join(script_dir, \"apikeys.yml\")\n",
    "\n",
    "    with open(file_path, 'r') as stream:\n",
    "        configs = yaml.safe_load(stream)\n",
    "        API_KEY = configs['openai']['api_key']\n",
    "            \n",
    "    return API_KEY\n",
    "path = r\"C:\\Users\\johna\\OneDrive\\Documents\\api_keys\"  # Change to the location of your apikeys.yml\n",
    "API_KEY = read_config(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864bf3ba-14a0-4079-b4dc-2795a14afe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "from haystack.utils import convert_files_to_docs\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# pre-process docs \n",
    "def preprocess_docs(doc_dir):\n",
    "    all_docs = convert_files_to_docs(dir_path=doc_dir)\n",
    "    preprocessor = PreProcessor(\n",
    "        clean_empty_lines=True,\n",
    "        clean_whitespace=True,\n",
    "        clean_header_footer=False,\n",
    "        split_by=\"word\",\n",
    "        split_respect_sentence_boundary=True,\n",
    "        split_overlap=30, \n",
    "        split_length=100\n",
    "    )\n",
    "    docs = preprocessor.process(all_docs)\n",
    "    print(f\"n_files_input: {len(all_docs)}\\nn_docs_output: {len(docs)}\")\n",
    "    return docs\n",
    "\n",
    "\n",
    "# create FAISS\n",
    "def vector_stores(docs):\n",
    "    engine = create_engine('sqlite:///C:/Users/johna/anaconda3/envs/longfunctioncall_env/long_functioncall/database/database.db')  # change to your local directory\n",
    "    try:\n",
    "        # Attempt to drop the table\n",
    "        engine.execute(\"DROP TABLE document\")\n",
    "    except Exception as e:\n",
    "        # Catch any exceptions, likely due to the table not existing\n",
    "        print(f\"Exception occurred while trying to drop the table: {e}\")\n",
    "    \n",
    "    document_store = FAISSDocumentStore(sql_url='sqlite:///C:/Users/johna/anaconda3/envs/longfunctioncall_env/long_functioncall/database/database.db', faiss_index_factory_str=\"Flat\", embedding_dim=768) # change to your local directory\n",
    "    document_store.write_documents(docs)\n",
    "    \n",
    "    return document_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e4ccb6-cdc5-46ff-9d7e-bb5b1be244d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:   0%|                                                                           | 0/1 [00:00<?, ?docs/s]We found one or more sentences whose word count is higher than the split length.\n",
      "Preprocessing: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.61docs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_files_input: 1\n",
      "n_docs_output: 1176\n",
      "Exception occurred while trying to drop the table: (sqlite3.OperationalError) no such table: document\n",
      "[SQL: DROP TABLE document]\n",
      "(Background on this error at: https://sqlalche.me/e/14/e3q8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing Documents: 10000it [00:02, 3442.53it/s]                                                                        \n"
     ]
    }
   ],
   "source": [
    "doc_dir = r\"C:\\Users\\johna\\anaconda3\\envs\\longfunctioncall_env\\long_functioncall\\knowledge_base\"\n",
    "docs = preprocess_docs(doc_dir)\n",
    "document_store = vector_stores(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c1bf61-e7d2-4878-a70f-23ad80ef18df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johna\\anaconda3\\envs\\longfunctioncall_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# define custom note OpenAIFunctionCall for our pipeline\n",
    "\n",
    "import openai\n",
    "from haystack.nodes.base import BaseComponent\n",
    "\n",
    "class OpenAIFunctionCall(BaseComponent):\n",
    "    outgoing_edges=1\n",
    "\n",
    "    def run(self, document: str):\n",
    "        functions = [\n",
    "        {\n",
    "            \"name\": \"write_to_df\",\n",
    "            \"description\": \"write the fund details to a dataframe\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prr\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The FCA product reference number which will be six or seven digits\"\n",
    "                    },\n",
    "                    \"investment_objective\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\"You should return a the investment objective of the fund.\n",
    "                        This is likely to be something like this: The Fund aims to grow your investment over t – t + delta t years\n",
    "                        \"\"\"\n",
    "                    },\n",
    "                    \"investment_policy\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\" Return a summary of the fund's investment policy, no more than a two sentences.\n",
    "                        \"\"\"\n",
    "                    },\n",
    "                    \"investment_strategy\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\" Return a summary of the fund's investment strategy, no more than a two sentences.\n",
    "                        \"\"\"\n",
    "                    },\n",
    "                    \"ESG\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\" Return either True, or False. True if the fund is an ESG fund, False otherwise.\n",
    "                        \"\"\"\n",
    "                    },\n",
    "                    \n",
    "                 },\n",
    "                },\n",
    "                \"required\": [\"prr\", \n",
    "                             \"investment_objective\", \n",
    "                             \"investment_policy\",\n",
    "                             \"investment_strategy\",\n",
    "                             \"ESG\"]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        openai.api_key = API_KEY\n",
    "        response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=[{\"role\": \"system\", \"content\": document}],\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "        )\n",
    "        response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "        return response_message\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a626b4f3-a91c-4cdf-9afc-8349ec77e347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johna\\anaconda3\\envs\\longfunctioncall_env\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Updating Embedding:   0%|                                                                  | 0/1163 [00:00<?, ? docs/s]\n",
      "Batches:   0%|                                                                                  | 0/37 [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "# create our pipeline\n",
    "from haystack import Pipeline\n",
    "from haystack.nodes import EmbeddingRetriever\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "    document_store=document_store,\n",
    "    embedding_model=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "document_store.update_embeddings(retriever)\n",
    "\n",
    "p = Pipeline()\n",
    "p.add_node(component=retriever, name=\"retriever\", inputs=[\"Query\"])\n",
    "p.add_node(component=OpenAIFunctionCall(), name=\"OpenAIFunctionCall\", inputs=[\"retriever\"])\n",
    "res = p.run(query=\"The FCA product reference number which will be six or seven digits\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce98aa5c-30e6-4fbc-baf7-56dcd850e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from haystack.nodes import EmbeddingRetriever, FARMReader\n",
    "# from haystack.pipelines import ExtractiveQAPipeline\n",
    "# from haystack.pipelines import Pipeline\n",
    "\n",
    "\n",
    "# # retreiver relevant docs\n",
    "# def make_document_qa_pipeline(document_store):\n",
    "#     retriever = EmbeddingRetriever(\n",
    "#         document_store=document_store,\n",
    "#         embedding_model=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "#     )\n",
    "#     document_store.update_embeddings(retriever)\n",
    "    \n",
    "#     # read relevant docs\n",
    "#     reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\")\n",
    "    \n",
    "#     document_qa = ExtractiveQAPipeline(reader=reader, retriever=retriever)\n",
    "#     return document_qa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
