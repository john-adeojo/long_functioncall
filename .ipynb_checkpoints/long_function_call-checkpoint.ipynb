{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f32bcf-dfdb-496a-80d8-10a090bdc77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import yaml\n",
    "def read_config(path):\n",
    "    \"\"\"\n",
    "    Reads API key from a configuration file.\n",
    "\n",
    "    This function opens a configuration file named \"apikeys.yml\", reads the API key for OpenAI\n",
    "\n",
    "    Returns:\n",
    "    api_key (str): The API key for the Amadeus Flights API.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the directory of the current script\n",
    "    script_dir = path\n",
    "\n",
    "    # Construct the full path to the configuration file\n",
    "    file_path = os.path.join(script_dir, \"apikeys.yml\")\n",
    "\n",
    "    with open(file_path, 'r') as stream:\n",
    "        configs = yaml.safe_load(stream)\n",
    "        API_KEY = configs['openai']['api_key']\n",
    "            \n",
    "    return API_KEY\n",
    "path = r\"C:\\Users\\johna\\OneDrive\\Documents\\api_keys\"  # Change to the location of your apikeys.yml\n",
    "API_KEY = read_config(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "864bf3ba-14a0-4079-b4dc-2795a14afe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johna\\anaconda3\\envs\\longfunctioncall_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "from haystack.utils import convert_files_to_docs\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# pre-process docs \n",
    "def preprocess_docs(doc_dir):\n",
    "    all_docs = convert_files_to_docs(dir_path=doc_dir)\n",
    "    preprocessor = PreProcessor(\n",
    "        clean_empty_lines=True,\n",
    "        clean_whitespace=True,\n",
    "        clean_header_footer=False,\n",
    "        split_by=\"word\",\n",
    "        split_respect_sentence_boundary=True,\n",
    "        split_overlap=30, \n",
    "        split_length=100\n",
    "    )\n",
    "    docs = preprocessor.process(all_docs)\n",
    "    print(f\"n_files_input: {len(all_docs)}\\nn_docs_output: {len(docs)}\")\n",
    "    return docs\n",
    "\n",
    "\n",
    "# create FAISS\n",
    "def vector_stores(docs):\n",
    "    engine = create_engine('sqlite:///C:/Users/johna/anaconda3/envs/longfunctioncall_env/long_functioncall/database/database.db')  # change to your local directory\n",
    "    try:\n",
    "        # Attempt to drop the table\n",
    "        engine.execute(\"DROP TABLE document\")\n",
    "    except Exception as e:\n",
    "        # Catch any exceptions, likely due to the table not existing\n",
    "        print(f\"Exception occurred while trying to drop the table: {e}\")\n",
    "    \n",
    "    document_store = FAISSDocumentStore(sql_url='sqlite:///C:/Users/johna/anaconda3/envs/longfunctioncall_env/long_functioncall/database/database.db', faiss_index_factory_str=\"Flat\", embedding_dim=768) # change to your local directory\n",
    "    document_store.write_documents(docs)\n",
    "    \n",
    "    return document_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e4ccb6-cdc5-46ff-9d7e-bb5b1be244d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:   0%|                                                                           | 0/1 [00:00<?, ?docs/s]We found one or more sentences whose word count is higher than the split length.\n",
      "Preprocessing: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.49docs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_files_input: 1\n",
      "n_docs_output: 1176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing Documents: 10000it [00:02, 3565.21it/s]                                                                        \n"
     ]
    }
   ],
   "source": [
    "doc_dir = r\"C:\\Users\\johna\\anaconda3\\envs\\longfunctioncall_env\\long_functioncall\\knowledge_base\"\n",
    "docs = preprocess_docs(doc_dir)\n",
    "document_store = vector_stores(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e78c7ca7-3233-4bd4-a63f-442637fc4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from haystack.nodes.base import BaseComponent\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "class OpenAIFunctionCall(BaseComponent):\n",
    "    outgoing_edges = 1\n",
    "\n",
    "    def run(self, documents: List[str]):\n",
    "        \n",
    "        # Try to extract the content and print the first few content strings\n",
    "        try:\n",
    "            document_content_list = [doc.content for doc in documents]\n",
    "            print(\"documents extracted\")\n",
    "            document_content = \" \".join(document_content_list)\n",
    "        except Exception as e:\n",
    "            print(\"Error extracting content:\", e)\n",
    "            return\n",
    "        functions = [\n",
    "            {\n",
    "                \"name\": \"update_dataframe\",\n",
    "                \"description\": \"write the fund details to a dataframe\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"Product_reference_num\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The FCA product reference number which will be six or seven digits\"\n",
    "                        },\n",
    "                        \"investment_objective\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"You should return the investment objective of the fund. This is likely to be something like this: The Fund aims to grow your investment over t – t + delta t years\"\n",
    "                        },\n",
    "                        \"investment_policy\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Return a summary of the fund's investment policy, no more than two sentences.\"\n",
    "                        },\n",
    "                        \"investment_strategy\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Return a summary of the fund's investment strategy, no more than two sentences.\"\n",
    "                        },\n",
    "                        \"ESG\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Return either True, or False. True if the fund is an ESG fund, False otherwise.\"\n",
    "                        },\n",
    "                        \"fund_name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Return the name of the fund\"\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"Product_reference_num\", \n",
    "                             \"investment_objective\", \n",
    "                             \"investment_policy\",\n",
    "                             \"investment_strategy\",\n",
    "                             \"ESG\",\n",
    "                             \"fund_name\"]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        openai.api_key = API_KEY\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=[{\"role\": \"system\", \"content\": document_content}],\n",
    "            functions=functions,\n",
    "            function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "        )\n",
    "\n",
    "        function_call_args = json.loads(response[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"])\n",
    "        \n",
    "        return function_call_args, \"output_1\"\n",
    "\n",
    "    def run_batch(self, documents: List[str]):\n",
    "        # You can either process multiple documents in a batch here or simply loop over the run method\n",
    "        results = []\n",
    "        for document_content in document_content:\n",
    "            result, _ = self.run(document_content)\n",
    "            results.append(result)\n",
    "        return results, \"output_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5e9984e-0624-4398-a291-ee1a91436646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johna\\anaconda3\\envs\\longfunctioncall_env\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Updating Embedding:   0%|                                                                  | 0/1163 [00:00<?, ? docs/s]\n",
      "Batches:   0%|                                                                                  | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:   3%|██                                                                        | 1/37 [00:29<17:45, 29.59s/it]\u001b[A\n",
      "Batches:   5%|████                                                                      | 2/37 [00:38<10:12, 17.49s/it]\u001b[A\n",
      "Batches:   8%|██████                                                                    | 3/37 [00:47<07:39, 13.53s/it]\u001b[A\n",
      "Batches:  11%|████████                                                                  | 4/37 [00:54<06:08, 11.17s/it]\u001b[A\n",
      "Batches:  14%|██████████                                                                | 5/37 [01:02<05:15,  9.86s/it]\u001b[A\n",
      "Batches:  16%|████████████                                                              | 6/37 [01:10<04:41,  9.07s/it]\u001b[A\n",
      "Batches:  19%|██████████████                                                            | 7/37 [01:16<04:10,  8.36s/it]\u001b[A\n",
      "Batches:  22%|████████████████                                                          | 8/37 [01:23<03:47,  7.85s/it]\u001b[A\n",
      "Batches:  24%|██████████████████                                                        | 9/37 [01:29<03:22,  7.22s/it]\u001b[A\n",
      "Batches:  27%|███████████████████▋                                                     | 10/37 [01:35<03:01,  6.73s/it]\u001b[A\n",
      "Batches:  30%|█████████████████████▋                                                   | 11/37 [01:41<02:52,  6.63s/it]\u001b[A\n",
      "Batches:  32%|███████████████████████▋                                                 | 12/37 [01:47<02:36,  6.26s/it]\u001b[A\n",
      "Batches:  35%|█████████████████████████▋                                               | 13/37 [01:53<02:28,  6.19s/it]\u001b[A\n",
      "Batches:  38%|███████████████████████████▌                                             | 14/37 [01:59<02:21,  6.15s/it]\u001b[A\n",
      "Batches:  41%|█████████████████████████████▌                                           | 15/37 [02:04<02:09,  5.88s/it]\u001b[A\n",
      "Batches:  43%|███████████████████████████████▌                                         | 16/37 [02:09<01:58,  5.63s/it]\u001b[A\n",
      "Batches:  46%|█████████████████████████████████▌                                       | 17/37 [02:14<01:47,  5.38s/it]\u001b[A\n",
      "Batches:  49%|███████████████████████████████████▌                                     | 18/37 [02:20<01:45,  5.55s/it]\u001b[A\n",
      "Batches:  51%|█████████████████████████████████████▍                                   | 19/37 [02:26<01:43,  5.73s/it]\u001b[A\n",
      "Batches:  54%|███████████████████████████████████████▍                                 | 20/37 [02:30<01:31,  5.40s/it]\u001b[A\n",
      "Batches:  57%|█████████████████████████████████████████▍                               | 21/37 [02:35<01:23,  5.25s/it]\u001b[A\n",
      "Batches:  59%|███████████████████████████████████████████▍                             | 22/37 [02:41<01:21,  5.43s/it]\u001b[A\n",
      "Batches:  62%|█████████████████████████████████████████████▍                           | 23/37 [02:47<01:17,  5.53s/it]\u001b[A\n",
      "Batches:  65%|███████████████████████████████████████████████▎                         | 24/37 [02:52<01:08,  5.29s/it]\u001b[A\n",
      "Batches:  68%|█████████████████████████████████████████████████▎                       | 25/37 [02:56<01:00,  5.02s/it]\u001b[A\n",
      "Batches:  70%|███████████████████████████████████████████████████▎                     | 26/37 [03:01<00:55,  5.03s/it]\u001b[A\n",
      "Batches:  73%|█████████████████████████████████████████████████████▎                   | 27/37 [03:06<00:49,  4.95s/it]\u001b[A\n",
      "Batches:  76%|███████████████████████████████████████████████████████▏                 | 28/37 [03:11<00:45,  5.03s/it]\u001b[A\n",
      "Batches:  78%|█████████████████████████████████████████████████████████▏               | 29/37 [03:15<00:38,  4.80s/it]\u001b[A\n",
      "Batches:  81%|███████████████████████████████████████████████████████████▏             | 30/37 [03:19<00:32,  4.59s/it]\u001b[A\n",
      "Batches:  84%|█████████████████████████████████████████████████████████████▏           | 31/37 [03:25<00:29,  4.89s/it]\u001b[A\n",
      "Batches:  86%|███████████████████████████████████████████████████████████████▏         | 32/37 [03:29<00:23,  4.63s/it]\u001b[A\n",
      "Batches:  89%|█████████████████████████████████████████████████████████████████        | 33/37 [03:33<00:17,  4.40s/it]\u001b[A\n",
      "Batches:  92%|███████████████████████████████████████████████████████████████████      | 34/37 [03:37<00:12,  4.20s/it]\u001b[A\n",
      "Batches:  95%|█████████████████████████████████████████████████████████████████████    | 35/37 [03:41<00:08,  4.10s/it]\u001b[A\n",
      "Batches:  97%|███████████████████████████████████████████████████████████████████████  | 36/37 [03:44<00:04,  4.02s/it]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████| 37/37 [03:45<00:00,  6.10s/it]\u001b[A\n",
      "Documents Processed: 10000 docs [03:46, 44.18 docs/s]                                                                  \n"
     ]
    }
   ],
   "source": [
    "# create our pipeline\n",
    "from haystack import Pipeline\n",
    "from haystack.nodes import EmbeddingRetriever\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "    document_store=document_store,\n",
    "    embedding_model=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "688beb35-3976-460f-a917-0758cef56d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents extracted\n"
     ]
    }
   ],
   "source": [
    "p = Pipeline()\n",
    "p.add_node(component=retriever, name=\"retriever\", inputs=[\"Query\"])\n",
    "p.add_node(component=OpenAIFunctionCall(), name=\"OpenAIFunctionCall\", inputs=[\"retriever\"])\n",
    "res = p.run(query=\"Get the details for the Global Sustain Fund\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dab918e3-90aa-4775-94ba-c454548e8f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Product_reference_num = res['Product_reference_num']\n",
    "investment_objective = res['investment_objective']\n",
    "investment_strategy = res['investment_strategy']\n",
    "investment_policy = res['investment_policy']\n",
    "ESG = res['ESG']\n",
    "fund_name = res['fund_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce98aa5c-30e6-4fbc-baf7-56dcd850e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def update_dataframe(prr, investment_objective, investment_strategy, investment_policy, ESG, fund_name):\n",
    "\n",
    "    # Define the columns\n",
    "    columns = ['Product_reference_num', 'fund_name', 'investment_objective', 'investment_strategy', 'investment_policy', 'ESG']\n",
    "    \n",
    "    # Create an empty DataFrame with the specified columns\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    # Create a dictionary for the new record\n",
    "    new_record = {\n",
    "        'Product_reference_num': Product_reference_num,\n",
    "        'fund_name': fund_name,\n",
    "        'investment_objective': investment_objective,\n",
    "        'investment_strategy': investment_strategy,\n",
    "        'investment_policy': investment_policy,\n",
    "        'ESG': ESG\n",
    "    }\n",
    "\n",
    "    # Check if a record with the given prr already exists\n",
    "    if Product_reference_num in df['Product_reference_num'].values:\n",
    "        # Update the existing record\n",
    "        idx = df[df['Product_reference_num'] == Product_reference_num].index[0]\n",
    "        df.loc[idx] = new_record\n",
    "    else:\n",
    "        # Convert the new record to a DataFrame\n",
    "        new_df = pd.DataFrame([new_record])\n",
    "        # Concatenate the existing DataFrame with the new record\n",
    "        df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4a37965-be21-48a6-8635-a9e51699ba9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_reference_num</th>\n",
       "      <th>fund_name</th>\n",
       "      <th>investment_objective</th>\n",
       "      <th>investment_strategy</th>\n",
       "      <th>investment_policy</th>\n",
       "      <th>ESG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>914072</td>\n",
       "      <td>Global Sustain Fund</td>\n",
       "      <td>The Fund aims to grow your investment over 5 -...</td>\n",
       "      <td>The Fund applies sustainability criteria and E...</td>\n",
       "      <td>The Fund invests at least 70% of its assets in...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product_reference_num            fund_name  \\\n",
       "0                914072  Global Sustain Fund   \n",
       "\n",
       "                                investment_objective  \\\n",
       "0  The Fund aims to grow your investment over 5 -...   \n",
       "\n",
       "                                 investment_strategy  \\\n",
       "0  The Fund applies sustainability criteria and E...   \n",
       "\n",
       "                                   investment_policy   ESG  \n",
       "0  The Fund invests at least 70% of its assets in...  True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = update_dataframe(prr, investment_objective, investment_strategy, investment_policy, ESG, fund_name)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b5f7eb-ca48-4a75-917a-f1f00135b59e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
